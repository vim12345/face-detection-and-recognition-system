
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition using YOLOv8 and FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Required Packages\n",
    "!pip install ultralytics keras mtcnn opencv-python tensorflow scikit-learn matplotlib imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Face Detection using YOLOv8\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "def detect_faces(image):\n",
    "    results = model(image)\n",
    "    faces = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            face = image[y1:y2, x1:x2]\n",
    "            faces.append(face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load FaceNet and Generate Embeddings\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "assert os.path.exists('facenet_keras.h5'), 'Download facenet_keras.h5 and place it in the working directory.'\n",
    "facenet_model = load_model('facenet_keras.h5')\n",
    "\n",
    "def preprocess_face(face, required_size=(160, 160)):\n",
    "    face = cv2.resize(face, required_size)\n",
    "    face = face.astype('float32')\n",
    "    mean, std = face.mean(), face.std()\n",
    "    face = (face - mean) / std\n",
    "    return np.expand_dims(face, axis=0)\n",
    "\n",
    "def get_embedding(model, face):\n",
    "    face = preprocess_face(face)\n",
    "    embedding = model.predict(face)\n",
    "    return embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build Embedding Database\n",
    "import os\n",
    "\n",
    "embedding_db = {}\n",
    "dataset_path = 'dataset'\n",
    "\n",
    "for person in os.listdir(dataset_path):\n",
    "    person_path = os.path.join(dataset_path, person)\n",
    "    embeddings = []\n",
    "    for img_name in os.listdir(person_path):\n",
    "        img_path = os.path.join(person_path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        faces = detect_faces(image)\n",
    "        if faces:\n",
    "            emb = get_embedding(facenet_model, faces[0])\n",
    "            embeddings.append(emb)\n",
    "    if embeddings:\n",
    "        embedding_db[person] = np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Face Recognition\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def recognize_face(face, database, threshold=0.7):\n",
    "    emb = get_embedding(facenet_model, face)\n",
    "    min_dist = 100\n",
    "    identity = None\n",
    "    for name, db_emb in database.items():\n",
    "        dist = norm(emb - db_emb)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    if min_dist < threshold:\n",
    "        return identity, min_dist\n",
    "    else:\n",
    "        return 'Unknown', min_dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
